# Model Inspection

Detailed analysis of individual model predictions, performance visualization, and export capabilities for production deployment.

## Overview

The Model Inspection tab allows you to examine specific models in detail, visualize predictions, and export model information.

**Key Features:**
- **Search & Filter** - Find models by keyword with pagination
- **Prediction Scatter Plots** - True vs predicted values with regression lines
- **Residual Analysis** - Identify systematic prediction errors
- **Model Details** - Parameters, training time, feature counts
- **Export Tools** - Download data and reproduction code

**Best For:** Model validation, selecting production models, understanding prediction quality, debugging failures

## Tab Location

**Navigation:** Dashboard â†’ Model Inspection (Tab 3)

## Section 1: Search and Filter

Efficient navigation through large result sets.

### Search Interface

**Keyword Search:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ” Search models...                 â”‚
â”‚ [random forest morgan_fp________]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Search Capabilities:**
- **Model names** - "random", "xgboost", "ridge"
- **Representations** - "morgan", "rdkit", "descriptors"
- **Combinations** - "xgboost morgan_fp"
- **Partial matches** - "rand" finds "RandomForest"

**Case-insensitive** - "XGBoost" = "xgboost" = "XGBOOST"

### Filtering Options

**Performance Threshold Filter:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Show only: RÂ² > [0.8___________]    â”‚
â”‚ Checkbox: â˜‘ Apply filter           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Displays only models above specified performance threshold.

**Top-N Selection:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Display top: [10___] models         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Shows only the N best-performing models.

### Pagination

For large result sets (100+ models):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Showing 1-100 of 345 results        â”‚
â”‚                                     â”‚
â”‚ [< Previous]  Page 1 of 4  [Next >]â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Features:**
- **100 models per page** - Optimal balance of detail and performance
- **Page navigation** - Previous/Next buttons
- **Jump to page** - Direct page selection
- **Result count** - Total matching models displayed

### Model Selection List

After filtering, models appear in a sortable list:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model                    | Representation  | RÂ²    | â–¼  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ XGBoost                  | morgan_fp_r2    | 0.856 | ğŸ” â”‚
â”‚ RandomForest             | morgan_fp_r2    | 0.842 | ğŸ” â”‚
â”‚ Ridge                    | rdkit_desc      | 0.798 | ğŸ” â”‚
â”‚ ...                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Click ğŸ” icon** to load model details and visualizations below.

## Section 2: Prediction Scatter Plot

Visualize how well the model's predictions match true experimental values.

### Plot Structure

```
Predicted
  1.0 â”¤            â€¢
      â”‚          â€¢ â€¢
  0.8 â”¤        â€¢â€¢â€¢
      â”‚      â€¢â€¢â€¢â€¢
  0.6 â”¤    â€¢â€¢â€¢â€¢
      â”‚  â€¢â€¢â€¢
  0.4 â”¤â€¢â€¢
      â”‚
  0.2 â”¤
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       0.2  0.4  0.6  0.8  1.0
                True Values

â€¢ Test data points
â”€ Perfect prediction line (y=x)
â”€ Fitted regression line
```

### Components

**Perfect Prediction Line (y = x):**
- Diagonal line from (0,0) to (1,1)
- If all predictions were perfect, points would fall on this line
- Gray dashed line

**Fitted Regression Line:**
- Linear fit through actual data points
- Shows systematic over/under-prediction
- Blue solid line
- Equation displayed: y = mx + b, RÂ²

**Data Points:**
- **Blue circles** - Test set predictions (default)
- **Orange circles** - Training set predictions (if "Show Train Data" enabled)
- **Size** - Scaled for visibility
- **Transparency** - Overlapping points visible

**Annotations:**
- **RÂ² value** - Correlation between predictions and true values
- **RMSE** - Root mean squared error
- **MAE** - Mean absolute error
- **N points** - Number of test samples

### Interpretation Guide

**Perfect Predictions:**
```
Predicted
  â”‚      â€¢
  â”‚    â€¢â€¢
  â”‚  â€¢â€¢
  â”‚â€¢â€¢
  â””â”€â”€â”€â”€â”€â”€â”€â”€
   True
```
All points on y=x line. RÂ² = 1.0. Model captures all variance.

**Good Predictions:**
```
Predicted
  â”‚     â€¢â€¢â€¢
  â”‚   â€¢â€¢â€¢
  â”‚ â€¢â€¢â€¢
  â”‚â€¢
  â””â”€â”€â”€â”€â”€â”€â”€â”€
   True
```
Points cluster near y=x line. RÂ² > 0.8. Reliable model.

**Systematic Overestimation:**
```
Predicted
  â”‚       â€¢
  â”‚      â€¢â€¢
  â”‚    â€¢â€¢     â† Points above
  â”‚  â€¢â€¢         y=x line
  â””â”€â”€â”€â”€â”€â”€â”€â”€
   True
```
Fitted line above y=x. Model consistently overestimates. Check calibration.

**Systematic Underestimation:**
```
Predicted
  â”‚  â€¢
  â”‚ â€¢â€¢         â† Points below
  â”‚â€¢â€¢            y=x line
  â”‚â€¢
  â””â”€â”€â”€â”€â”€â”€â”€â”€
   True
```
Fitted line below y=x. Model consistently underestimates.

**Heteroscedastic Errors:**
```
Predicted
  â”‚        â€¢
  â”‚      â€¢â€¢â€¢    â† Spread increases
  â”‚    â€¢â€¢â€¢â€¢â€¢â€¢
  â”‚  â€¢â€¢â€¢
  â””â”€â”€â”€â”€â”€â”€â”€â”€
   True
```
Error variance increases with value. Consider log transformation or different model.

**Outliers:**
```
Predicted
  â”‚          â€¢  â† Far from line
  â”‚    â€¢â€¢â€¢
  â”‚  â€¢â€¢â€¢
  â”‚ â€¢
  â””â”€â”€â”€â”€â”€â”€â”€â”€
   True
```
Few points far from regression line. Investigate: data errors? difficult molecules?

**Random Scatter (Poor Model):**
```
Predicted
  â”‚  â€¢ â€¢  â€¢
  â”‚ â€¢   â€¢
  â”‚  â€¢    â€¢  â† No pattern
  â”‚ â€¢  â€¢
  â””â”€â”€â”€â”€â”€â”€â”€â”€
   True
```
No correlation between predicted and true. RÂ² â‰ˆ 0. Model failed.

### Interactive Features

**Hover Over Points:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SMILES: CCO            â”‚
â”‚ True: 0.72             â”‚
â”‚ Predicted: 0.68        â”‚
â”‚ Error: -0.04           â”‚
â”‚ Residual: -0.04        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
Shows molecule identifier, true value, prediction, and error.

**Zoom:**
- Click and drag to zoom into region
- Double-click to reset zoom
- Useful for examining dense clusters

**Show/Hide Training Data:**
```
Checkbox: â˜ Show Training Data
```
- **Enabled** - Displays both train (orange) and test (blue) points
- **Disabled** - Shows only test data (default)

**Why Compare Train vs Test:**
- **Train points much better than test** â†’ Overfitting
- **Train and test similar** â†’ Good generalization
- **Both poor** â†’ Underfitting or difficult task

### Use Cases

âœ… **Model validation** - Is RÂ² consistent with cross-validation?
âœ… **Outlier identification** - Which molecules are poorly predicted?
âœ… **Systematic bias** - Is there over/under-prediction pattern?
âœ… **Heteroscedasticity** - Does error variance change with magnitude?
âœ… **Publication figures** - High-quality scatter plots

## Section 3: Residual Analysis

Examine prediction errors to identify systematic patterns.

### Residual Plot

```
Residual
  0.2 â”¤    â€¢
      â”‚  â€¢ â€¢
  0.0 â”¤â€¢â€¢â€¢â€¢â€¢â€¢â€¢  â† Ideally random scatter
      â”‚  â€¢ â€¢      around zero
 -0.2 â”¤    â€¢
      â””â”€â”€â”€â”€â”€â”€â”€â”€
       0.2  0.8
     Predicted Value
```

**Residual = True Value - Predicted Value**

### Components

**Zero Line:**
- Horizontal line at y=0
- Perfect predictions would all be on this line

**Residual Points:**
- **Above zero** - Model underestimated
- **Below zero** - Model overestimated
- **Distance from zero** - Magnitude of error

### Interpretation Guide

**Random Pattern (Good):**
```
Residual
  â”‚  â€¢ â€¢
  â”‚â€¢  â€¢  â€¢
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€  â† No pattern
  â”‚ â€¢  â€¢
  â”‚  â€¢
```
Points randomly scattered around zero. No systematic bias. Good model.

**Systematic Underestimation (Poor):**
```
Residual
  â”‚ â€¢â€¢â€¢
  â”‚â€¢â€¢â€¢â€¢â€¢
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€  â† All positive
  â”‚
  â”‚
```
All residuals positive. Model consistently underestimates. Needs calibration.

**Systematic Overestimation (Poor):**
```
Residual
  â”‚
  â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€  â† All negative
  â”‚â€¢â€¢â€¢â€¢â€¢
  â”‚ â€¢â€¢â€¢
```
All residuals negative. Model consistently overestimates.

**Funnel Pattern (Heteroscedasticity):**
```
Residual
  â”‚      â€¢
  â”‚    â€¢â€¢â€¢    â† Spread increases
  â”‚  â€¢â€¢â€¢â€¢â€¢      (funnel shape)
  â”œâ”€â”€â”€â€¢â€¢â”€â”€
  â”‚  â€¢â€¢â€¢
```
Error variance increases with predicted value. Consider transformation or different model.

**Non-linear Pattern (Model Misspecification):**
```
Residual
  â”‚ â€¢      â€¢
  â”‚  â€¢â€¢â€¢â€¢â€¢    â† Curved pattern
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€
  â”‚  â€¢â€¢â€¢
  â”‚ â€¢    â€¢
```
Curved residual pattern. Linear model insufficient. Try non-linear models.

### Use Cases

âœ… **Bias detection** - Identify systematic over/under-prediction
âœ… **Heteroscedasticity check** - Is error variance constant?
âœ… **Model assumptions** - Validate linear model appropriateness
âœ… **Error patterns** - Find non-random error structure

## Section 4: Model Details

Comprehensive information about model configuration and performance.

### Model Information Panel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model Configuration                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Model: XGBoost                      â”‚
â”‚ Representation: morgan_fp_r2_1024   â”‚
â”‚ Features: 1,024                     â”‚
â”‚ Training Time: 12.34 seconds        â”‚
â”‚                                     â”‚
â”‚ Performance Metrics:                â”‚
â”‚  RÂ²: 0.856                          â”‚
â”‚  RMSE: 0.423                        â”‚
â”‚  MAE: 0.312                         â”‚
â”‚  Pearson R: 0.925                   â”‚
â”‚                                     â”‚
â”‚ Cross-Validation:                   â”‚
â”‚  Mean: 0.852 Â± 0.012               â”‚
â”‚  Folds: [0.849, 0.867, 0.851,       â”‚
â”‚          0.849, 0.844]              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Model Parameters

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Hyperparameters                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ n_estimators: 200                   â”‚
â”‚ learning_rate: 0.1                  â”‚
â”‚ max_depth: 6                        â”‚
â”‚ subsample: 0.8                      â”‚
â”‚ colsample_bytree: 0.8              â”‚
â”‚ random_state: 42                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Shows exact configuration for reproducibility.

### Representation Configuration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Representation Details              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Type: Fingerprint                   â”‚
â”‚ Modality: VECTOR                    â”‚
â”‚ Algorithm: Morgan (Circular)        â”‚
â”‚ Radius: 2                           â”‚
â”‚ Bits: 1024                          â”‚
â”‚ Use Features: No                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Section 5: Export Tools

Download model data and generate reproduction code.

### Export Model Data as CSV

**Button:** "Download Model Data (CSV)"

**Contents:**
```csv
molecule_id,true_value,predicted_value,residual
mol_001,0.72,0.68,-0.04
mol_002,0.85,0.89,0.04
mol_003,0.54,0.51,-0.03
...
```

**Use For:**
- Offline analysis in Excel/Python
- Sharing results with collaborators
- Custom visualization tools
- Quality control checks

### Generate Reproduction Code

**Button:** "Generate Reproduction Code"

**Output:**
```python
# Reproduction code for best model
from polyglotmol.data import MolecularDataset
from polyglotmol.representations import get_featurizer
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
import joblib

# 1. Load and prepare data
dataset = MolecularDataset.from_csv(
    "molecules.csv",
    input_column="SMILES",
    label_columns=["activity"]
)

# 2. Generate representation
featurizer = get_featurizer("morgan_fp_r2_1024")
X = featurizer.transform(dataset.smiles)
y = dataset.labels["activity"]

# 3. Train-test split (same seed for reproducibility)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 4. Train model with exact parameters
model = RandomForestRegressor(
    n_estimators=200,
    max_depth=10,
    min_samples_split=2,
    random_state=42,
    n_jobs=-1
)
model.fit(X_train, y_train)

# 5. Evaluate
y_pred = model.predict(X_test)
test_r2 = r2_score(y_test, y_pred)
print(f"Test RÂ²: {test_r2:.3f}")

# 6. Save model
joblib.dump(model, 'production_model.pkl')

# 7. Load and use later
# model = joblib.load('production_model.pkl')
# predictions = model.predict(new_X)
```

**Code Features:**
- **Complete workflow** - From data loading to model saving
- **Exact parameters** - Reproduces dashboard results
- **Comments** - Explains each step
- **Ready to run** - Copy-paste into Python script

### Save Best Model

After identifying your production model:

```python
# From your Python environment after screening
import joblib

# Get best model from screening results
best_model = results['best_estimator']

# Save to disk
joblib.dump(best_model, 'my_production_model.pkl')

# Later: Load and use
loaded_model = joblib.load('my_production_model.pkl')
predictions = loaded_model.predict(new_features)
```

## Practical Workflows

### Workflow 1: Finding Production Model

**Goal:** Select best model for deployment

1. **Review Performance Analysis tab** â†’ Note top 3 models
2. **Switch to Model Inspection tab**
3. **Search for each top model**
4. **For each model:**
   - Check prediction scatter plot RÂ²
   - Examine residual plot for bias
   - Review training time (if deployment speed matters)
   - Note parameter complexity

5. **Decision criteria:**
   - **Highest RÂ²** â†’ Best accuracy
   - **Lowest residual bias** â†’ Most calibrated
   - **Fastest training** â†’ Easier to retrain
   - **Simplest parameters** â†’ Easier to maintain

6. **Export winner:**
   - Generate reproduction code
   - Download model data CSV
   - Document model details

### Workflow 2: Debugging Poor Performance

**Goal:** Understand why a model fails

1. **Search for poorly performing model**
2. **Load prediction scatter plot**
3. **Diagnose issue:**

   **If RÂ² very low (<0.3):**
   - Random scatter â†’ Wrong representation/model
   - Check if different modality needed

   **If systematic bias (all above/below line):**
   - Model miscalibrated
   - Consider calibration techniques

   **If many outliers:**
   - Hover over outliers â†’ Note molecule IDs
   - Check if outliers share structural features
   - May need feature engineering

   **If heteroscedastic (funnel pattern):**
   - Error variance not constant
   - Try log-transforming target variable
   - Or use quantile regression

4. **Action:**
   - Switch to better representation/model
   - Or refine dataset (remove outliers)
   - Or apply transformations

### Workflow 3: Model Comparison

**Goal:** Compare two similar-performing models

1. **Search first model** (e.g., "xgboost morgan")
2. **Note:**
   - RÂ² and RMSE
   - Residual pattern
   - Training time

3. **Search second model** (e.g., "random_forest morgan")
4. **Compare:**
   - Which has higher RÂ²?
   - Which has less bias (residual plot)?
   - Which trains faster?
   - Which has simpler parameters?

5. **Decision:**
   - If similar accuracy: Choose faster/simpler
   - If accuracy differs: Choose more accurate
   - Consider ensemble of both

### Workflow 4: Outlier Investigation

**Goal:** Understand why certain molecules are poorly predicted

1. **Load best model in Model Inspection**
2. **Zoom into outlier region** of scatter plot
3. **Hover over outlier points** â†’ Note SMILES
4. **Record outlier molecules:**
   ```
   SMILES: CC(C)C1=CC=C(C=C1)C(C)C(O)=O
   True: 2.34
   Predicted: 0.87
   Error: -1.47
   ```

5. **Analyze outlier structures:**
   - Do they share common substructures?
   - Are they chemically unusual?
   - Data quality issues (measurement errors)?

6. **Actions:**
   - If systematic: Add relevant features
   - If rare structures: Collect more similar data
   - If data errors: Correct or remove

## Tips and Best Practices

```{admonition} Model Inspection Tips
:class: tip

1. **Always check residual plot** - Scatter RÂ² can be misleading
2. **Use keyword search** - Faster than scrolling through lists
3. **Compare train vs test** - Detect overfitting early
4. **Export reproduction code** - Document for future reference
5. **Hover for details** - Every point has molecule-level information
6. **Pagination helps** - Don't be overwhelmed by 100+ models
```

```{admonition} Red Flags to Watch For
:class: warning

- **Train RÂ² >> Test RÂ²** - Overfitting, model won't generalize
- **Funnel residuals** - Heteroscedasticity, model assumptions violated
- **Systematic bias** - All residuals positive/negative, needs calibration
- **Many outliers** - Data quality or representation issues
- **Curved residual pattern** - Non-linear relationship, wrong model type
```

## Performance Notes

**For Large Result Sets (1000+ models):**
- Pagination automatically enabled (100/page)
- Search and filters reduce displayed models
- Scatter plots cached for speed
- Residual plots computed on-demand

**Optimization Tips:**
- Use keyword search to narrow results
- Apply performance threshold filters
- Close other browser tabs
- Clear browser cache if slow

## Next Steps

- **Compare distributions**: {doc}`distributions` - See how this model fits overall distribution
- **Performance overview**: {doc}`performance` - Compare with other models
- **Get started**: {doc}`quickstart` - Launch the dashboard
